{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(dir_name):\n",
    "    return os.listdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(file_list):\n",
    "    y_class = []\n",
    "    x_text = []\n",
    "    class_dict = {1: '0', 2: '0', 3: '0', 4: '0', 5: '1', 6: '1', 7: '1', 8: '1'}\n",
    "    for file_name in file_list:\n",
    "        try:\n",
    "            with open(file_name, 'r', encoding='utf8') as f:\n",
    "                category = int(file_name.split(os.sep)[1].split('_')[0])\n",
    "                y_class.append(class_dict[category])\n",
    "                x_text.append(f.read())\n",
    "            f.close()\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(e)\n",
    "            print(file_name)\n",
    "    return x_text, y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_text(text):\n",
    "    text = re.sub('\\n+', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_dict(text):\n",
    "    text = [article.split() for article in text]\n",
    "    cleaned_words = [get_cleaned_text(word) for article in text for word in article]\n",
    "    corpus_dict = OrderedDict()\n",
    "    for i, v in enumerate(set(cleaned_words)):\n",
    "        corpus_dict[v] = i\n",
    "    return corpus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_vector(text, corpus):\n",
    "    text = [article.split() for article in text]\n",
    "    word_index_list = [[corpus[get_cleaned_text(word)] for word in article] for article in text]\n",
    "    x_vector = [[0 for _ in range(len(corpus))] for i in range(len(text))]\n",
    "    for ind, text in enumerate(word_index_list):\n",
    "        for i in text:\n",
    "            x_vector[ind][i] += 1\n",
    "    return x_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(v1, v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]\n",
    "        y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(x_vector, source):\n",
    "    source_vector = x_vector[source]\n",
    "    similarity_list =[]\n",
    "    for target_vector in x_vector:\n",
    "        similarity_list.append(get_cosine_similarity(source_vector, target_vector))\n",
    "    return similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similarity_news(similarity_score, n):\n",
    "    x = {i: v for i, v in enumerate(similarity_score)}\n",
    "    sorted_x = sorted(x.items(), key=operator.itemgetter(1))\n",
    "    return list(reversed(sorted_x))[1:n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'news_data'\n",
    "file_list = get_file_list(dir_name)\n",
    "file_list = [os.path.join(dir_name, file_name) for file_name in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xa1 in position 79: invalid start byte\n",
      "news_data/8_Heung Min Son gives Tottenham a two-goal advantage vs Chelsea.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 566: invalid start byte\n",
      "news_data/8_Has Heung Min Son Done Enough to Justify 22m Transfer.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 205: invalid start byte\n",
      "news_data/8_South Korea coach has a warning for Tottenham Hotspur's Heung-min Son and fellow internationals, suggests they should consider exits.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 442: invalid start byte\n",
      "news_data/1_Seattle Mariners' Newest Signing Dae-Ho Lee Could Become Fan Favorite.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 34: invalid start byte\n",
      "news_data/8_Heung min Son Believes Injury Tainted Debut at Tottenham.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 324: invalid start byte\n",
      "news_data/4_Byung-Ho Park Won't Fix The Minnesota Twins.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 288: invalid start byte\n",
      "news_data/4_Twins’ Byung Ho Park Still Getting Accustomed To American Life.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 895: invalid start byte\n",
      "news_data/1_Korean First Baseman Dae-Ho Lee Becomes Free Agent, Interested In MLB Deal.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 511: invalid start byte\n",
      "news_data/5_S. Korean MF Koo Ja-cheol suspended for next World Cup qualifier.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 539: invalid start byte\n",
      "news_data/4_Park Byung-ho hits large homer on ‘Park Byung-ho Day’.txt\n",
      "'utf-8' codec can't decode byte 0xa9 in position 418: invalid start byte\n",
      "news_data/6_BVB has initially without full-back Joo-Ho Park.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 95: invalid start byte\n",
      "news_data/4_Minnesota’s Park Byung-ho hits 7th homer of the season.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 184: invalid start byte\n",
      "news_data/2_Dodgers left with questions after latest Hyun-Jin Ryu setback.txt\n",
      "'utf-8' codec can't decode byte 0xa9 in position 870: invalid start byte\n",
      "news_data/5_Koo Ja-cheol Nets a Hat Trick for Augsburg.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 296: invalid start byte\n",
      "news_data/2_Ryu Hyun-jin suffers injury in groin, further delays return.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 431: invalid start byte\n",
      "news_data/2_Hyun-Jin Ryu downplays long break between bullpen sessions.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 47: invalid start byte\n",
      "news_data/1_Mariners’ Lee Dae-ho gets 1st two-hit game, double.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 133: invalid start byte\n",
      "news_data/5_Stielike warns it won't be easy for Euro-stars.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 708: invalid start byte\n",
      "news_data/5_Augsburg vs Stuttgart Bundesliga Match Preview and Kick-Off Time.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 679: invalid start byte\n",
      "news_data/8_Who Should Be Tottenham Hotspur's No. 1 Summer Transfer Target.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 1440: invalid start byte\n",
      "news_data/5_Augsburg midfielder Koo Ja-cheol scores 3 hat tricks at home game.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 642: invalid start byte\n",
      "news_data/2_Hyun-Jin Ryu's timetable starting to become clear.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 197: invalid start byte\n",
      "news_data/2_Ryu Hyun-jin appears before fans after 3-month hiatus for rehabilitation.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 208: invalid start byte\n",
      "news_data/7_Ki Sung-Yueng back in Swansea City fold as Garry Monk targets victory over benchmark club Everton.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 268: invalid start byte\n",
      "news_data/7_Swansea win the perfect tonic for weary Sunderland.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 769: invalid start byte\n",
      "news_data/4_Twins' slugger Byung Ho Park adapts to high heat.txt\n",
      "'utf-8' codec can't decode byte 0xa1 in position 270: invalid start byte\n",
      "news_data/2_Dodgers unsure when Hyun-Jin Ryu will throw another bullpen session.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(8, 0.5680173387061597),\n",
       " (45, 0.5397291783046336),\n",
       " (49, 0.5248421614892682),\n",
       " (46, 0.5122499547064614),\n",
       " (33, 0.5105967831132049),\n",
       " (18, 0.5072683932973394),\n",
       " (21, 0.4970233221930489),\n",
       " (50, 0.4896786216523619),\n",
       " (24, 0.48412440135706775),\n",
       " (52, 0.48125194037488966)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text, y_class = get_contents(file_list)\n",
    "corpus = get_corpus_dict(x_text)\n",
    "x_vector = get_count_vector(x_text, corpus)\n",
    "similarity_score = get_similarity_score(x_vector, 0)\n",
    "get_top_n_similarity_news(similarity_score, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit7dfa4987a5f7442ebd81ff5dfdf02ba8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
